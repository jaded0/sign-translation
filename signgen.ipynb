{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4776201a-e5c2-4ff4-bac0-8d9885eedb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b79c8317024aeba4c91ece125538a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/beartype/_util/hint/pep/utilpeptest.py:345: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.List[str] deprecated by PEP 585 scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". See this discussion for further details and alternatives:\n",
      "    https://github.com/beartype/beartype#pep-585-deprecations\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install -q imagen-pytorch==1.17.0\n",
    "# !pip install -q yagmail[all]\n",
    "# !pip uninstall -q lxml\n",
    "# !pip install -q lxml\n",
    "\n",
    "import torch\n",
    "from imagen_pytorch import Unet3D, ElucidatedImagen, ImagenTrainer\n",
    "from nslt_dataset import NSLT\n",
    "import torchvision.transforms as T\n",
    "import ipywidgets as widgets\n",
    "from emailme import send_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cf5a4b-b61c-495f-8412-24b9bd85e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send_email('./samples/', ['sample-22_book.gif'], 'yeaaah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cc5991-6c84-4927-a91b-cbb6fe6755f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet1 = Unet3D(\n",
    "    dim = 128, \n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    \n",
    "    lowres_cond = True,\n",
    "    image_embed_dim = 32,\n",
    ").cuda()\n",
    "\n",
    "unet2 = Unet3D(\n",
    "    dim = 128, \n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    \n",
    "    lowres_cond = True,\n",
    "    image_embed_dim = 32,\n",
    ").cuda()\n",
    "\n",
    "# elucidated imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = ElucidatedImagen(\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (16, 64),\n",
    "    random_crop_sizes = (None, 8),\n",
    "    num_sample_steps = 10,\n",
    "    cond_drop_prob = 0.1,\n",
    "    sigma_min = 0.002,                          # min noise level\n",
    "    sigma_max = (80, 160),                      # max noise level, double the max noise level for upsampler\n",
    "    sigma_data = 0.5,                           # standard deviation of data distribution\n",
    "    rho = 7,                                    # controls the sampling schedule\n",
    "    P_mean = -1.2,                              # mean of log-normal distribution from which noise is drawn for training\n",
    "    P_std = 1.2,                                # standard deviation of log-normal distribution from which noise is drawn for training\n",
    "    S_churn = 30,                               # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n",
    "    S_tmin = 0.01,\n",
    "    S_tmax = 1,\n",
    "    S_noise = 1.007,\n",
    "    # text_encoder_name = 't5-large',\n",
    "    \n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62de8d5d-deeb-4b3d-bff4-de2261ac59e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ae0c4fea324669a7448eca49d78e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/945M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dc452ecfe144019c0e7c4933f441a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccef148c9a7457e81fa2187ecf7733a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f4ecc5e6234554a9266ccd393e0e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped videos:  0\n",
      "1780\n",
      "Skipped videos:  0\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "mode = 'rgb'\n",
    "root = {'word': './WLASL2000/'}\n",
    "\n",
    "dataset = NSLT('./preprocess/nslt_100.json', 'train', root=root, mode='rgb', transforms=None)\n",
    "val_dataset = NSLT('./preprocess/nslt_100.json', 'test', root=root, mode='rgb', transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f1b1e2-5a19-4b73-9009-9878fcf3a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in enumerate(dataset, 0):\n",
    "#     if x<3:\n",
    "#         print(y[0].size())\n",
    "#         print(y[1])\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0052a5cf-5317-48dd-b42b-d377a6b88718",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen,\n",
    "    lr = 1e-4,\n",
    "    \n",
    ").cuda()\n",
    "trainer.add_train_dataset(dataset, batch_size=batch_size)\n",
    "trainer.add_valid_dataset(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21191b6-11a0-43cf-b64b-b5edef0fadbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'book',\n",
    "    'deaf',\n",
    "    'fine',\n",
    "    'yes',\n",
    "    'cool',\n",
    "]\n",
    "# trainer.save(f'./checkpoint{1}.pt')\n",
    "# trainer.load(f'checkpoint{1}.pt')\n",
    "# trainer.load(f'checkpoint{2}.pt')\n",
    "# loss = trainer.train_step(unet_number = unet_training, max_batch_size = 4)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735bf677-2519-40c5-9d7f-9dea7c291fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded from checkpoint2.pt\n",
      "avg_loss: 0.1657245621085167\n",
      "avg_loss: 0.20621512413024903\n",
      "valid loss: 0.11265818029642105, total avg loss: 0.18814878346025943\n",
      "avg_loss: 0.1645312238484621\n",
      "avg_loss: 0.16919931482523679\n",
      "valid loss: 0.2581879496574402, total avg loss: 0.17348799180984498\n",
      "on step 1000, avg loss of last 1000 steps: 0.18076613912364461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bce119cf5014f06bde4c19122e99775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa6e1c285504d5e8a1d1fc8a51d48eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5118e81faa9464ea61eb29c08e64d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d72ef4c2fa423a9a11452b1318388d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xce\\xe6\\xe2\\xb2\\xe2\\xd8\\xad\\xe2\\xd5\\xaa\\xe4\\xd2\\xa9\\xdc\\xce\\xa4\\xe7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acf5bdd68d644928771810139ebb5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\x9f\\xed\\xe4\\x9e\\xe6\\xdd\\x94\\xe9\\xd6\\x9b\\xe1\\xd9\\x95\\xe2\\xd6\\x93\\xe1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.1678640579432249\n",
      "avg_loss: 0.18788486570119858\n",
      "valid loss: 0.1605975478887558, total avg loss: 0.18092206566780805\n",
      "avg_loss: 0.17355257600545884\n",
      "avg_loss: 0.16076122596859932\n",
      "valid loss: 0.08762858808040619, total avg loss: 0.17338728019595145\n",
      "on step 2000, avg loss of last 1000 steps: 0.17715467293187975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97ce398cacd438d95ae6bbf9ce13457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec5a545088e4ee0bb094a76b8d8ee70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a97c32231494b41963d237ec5e19a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80d3c9f5080404cbcce4b75345815e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xa5\\xe5\\xc9\\xa1\\xe1\\xcd\\xa0\\xe0\\xca\\xa4\\xdd\\xc6\\x9c\\xdd\\xcc\\xad\\xd9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c2b71adc3f47b9830f8c017e3e1e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xbf\\xe4\\xd1\\xac\\xe1\\xd7\\xb4\\xda\\xcd\\xb6\\xd1\\xcc\\xa3\\xd0\\xc9\\x90\\xdc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved to ./checkpoint2.pt\n",
      "avg_loss: 0.1710332153737545\n",
      "avg_loss: 0.1903467185050249\n",
      "valid loss: 0.17666348814964294, total avg loss: 0.1765720390677452\n",
      "avg_loss: 0.2141426555067301\n",
      "avg_loss: 0.17541252456605436\n",
      "valid loss: 0.17546993494033813, total avg loss: 0.1799412784576416\n",
      "on step 3000, avg loss of last 1000 steps: 0.1782566587626934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894827424c804793a214c950bc436556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8fe862bf8a4b429e902f23829d8ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41726b10ba1f4500b0d7bf0b3377c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18b021c427481f9a98831d6c127f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xb8\\xec\\xeb\\x9c\\xdf\\xda\\x90\\xdf\\xd9\\x8f\\xda\\xd0\\xa1\\xd3\\xd2\\x94\\xd3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74af9984a1f9466cb7e3fc50fbefafe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xba\\xf3\\xe4\\xac\\xee\\xdf\\xa4\\xf1\\xe5\\xa0\\xec\\xdc\\xa2\\xea\\xe0\\xa7\\xe4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 0.16432345174252988\n",
      "avg_loss: 0.16644683688879014\n",
      "valid loss: 0.21089644730091095, total avg loss: 0.17458262219280005\n",
      "avg_loss: 0.17761773619800805\n",
      "avg_loss: 0.18426691085100175\n",
      "valid loss: 0.06389383971691132, total avg loss: 0.16788379007577897\n",
      "on step 4000, avg loss of last 1000 steps: 0.1712332061342895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaa62b3b0c7432481fe12aacb998b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036cdbf1d73435ba50350071f4e2895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fbc1bf528040c6bd940dc7363d7b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c04468bc8e148f592877a1eeec5700a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xa3\\xea\\xe2\\x97\\xdd\\xd9\\xa7\\xda\\xda\\x8e\\xd9\\xd1\\x9d\\xd6\\xd5\\x8e\\xd6…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fea9bf8a0c46f5b4ac543c233cab9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'GIF89a@\\x00@\\x00\\x87\\x00\\x00\\xc8\\xe6\\xe0\\xb7\\xe4\\xd8\\xc3\\xda\\xdc\\xb6\\xdb\\xdd\\xaa\\xde\\xd5\\xa7\\xd9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved to ./checkpoint2.pt\n",
      "avg_loss: 0.18532417714595795\n",
      "avg_loss: 0.17001347687095403\n",
      "valid loss: 0.13566994667053223, total avg loss: 0.17616512279957533\n"
     ]
    }
   ],
   "source": [
    "def go():\n",
    "    unet_training = 2\n",
    "    trainer.load(f'checkpoint{2}.pt')\n",
    "    max_batch_size = 4\n",
    "    running_totals = []\n",
    "    overview = []\n",
    "    \n",
    "    for i in range(100000):\n",
    "        loss = trainer.train_step(unet_number = unet_training, max_batch_size = max_batch_size)\n",
    "        running_totals.append(loss)\n",
    "\n",
    "        if not (i % 250) and not i==0:\n",
    "            print(f'avg_loss: {sum(running_totals[-100:])/100}')\n",
    "        if not (i % 500) and not i==0:\n",
    "            valid_loss = trainer.valid_step(unet_number = unet_training, max_batch_size = max_batch_size)\n",
    "            print(f'valid loss: {valid_loss}, total avg loss: {sum(running_totals[-500:])/500}')\n",
    "\n",
    "        if not (i % 1000) and not i==0 and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "            overview_total = sum(running_totals)/len(running_totals)\n",
    "            print(f'on step {i}, avg loss of last 1000 steps: {overview_total}')\n",
    "            del running_totals[:]\n",
    "            overview.append(overview_total)\n",
    "            videos = trainer.sample(texts = texts, video_frames = 20, stop_at_unet_number=unet_training)\n",
    "            # catch the images and animate them.\n",
    "            pil_images = list(map(    lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))),    videos.swapdims(2,1)    ))\n",
    "            for x,img in enumerate(pil_images):\n",
    "                img[0].save(f'./samples/sample-{i//1000}_{texts[x]}.gif', format='GIF', save_all = True, \n",
    "                            append_images = pil_images[x][1:],\n",
    "                            optimize = False, duration = 200, loop=0,\n",
    "                            disposal=3,\n",
    "                           )\n",
    "            display(widgets.Image(value = open(f'./samples/sample-{i//1000}_book.gif','rb').read(),\n",
    "                 format='gif',\n",
    "                 width=512,\n",
    "                 height=512,\n",
    "                 ))\n",
    "            display(widgets.Image(value = open(f'./samples/sample-{i//1000}_yes.gif','rb').read(),\n",
    "                 format='gif',\n",
    "                 width=512,\n",
    "                 height=512,\n",
    "                 ))\n",
    "            \n",
    "        if not (i % 2000) and not (i==0):\n",
    "            trainer.save(f'./checkpoint{unet_training}.pt')\n",
    "            \n",
    "        if not (i%4000):\n",
    "            updates = \"updates:\\n\" + \"\\n\".join([f'{x:.4f}' for x in overview])\n",
    "            send_email('./samples/', [f'sample-{i//1000}_{x}.gif' for x in texts], updates)\n",
    "\n",
    "    trainer.save(f'./checkpoint{unet_training}.pt')\n",
    "\n",
    "go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8fcb90-a183-4787-9311-f7ca3d528211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90029a48-c151-412b-b9c9-c2ea9d299deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = trainer.sample(texts = texts, video_frames = 40) # extrapolating to 20 frames from training on 10 frames\n",
    "\n",
    "videos.shape # (4, 3, 20, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c61c7b-de59-451b-ab54-a0a9342a74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01af29-c27c-42cb-9e68-54e00ab5b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_images = list(map(    lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))),    videos.swapdims(2,1)    ))\n",
    "for x,img in enumerate(pil_images):\n",
    "    img[0].save(f'{texts[x]}.gif', format='GIF', save_all = True, \n",
    "                append_images = pil_images[x][1:],\n",
    "                optimize = False, duration = 100, loop=0,\n",
    "                disposal=3,\n",
    "               )\n",
    "    print(f'{texts[x]} signed:')\n",
    "    display(widgets.Image(value = open(f'{texts[x]}.gif','rb').read(),\n",
    "             format='gif',\n",
    "             width=512,\n",
    "             height=512,\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7848d-55e3-435d-bd2c-22f401cd7096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e8b24-503f-4ea6-8f72-2302f1a26df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = ImagenTrainer(imagen).cuda()\n",
    "# trainer.add_train_dataset(dataset, batch_size=4)\n",
    "# trainer.add_valid_dataset(val_dataset, batch_size=4)\n",
    "# unet_training = 2\n",
    "# trainer.load(f'./checkpoint{1}.pt')\n",
    "# for i in range(1000):\n",
    "#     loss = trainer.train_step(unet_number = unet_training, max_batch_size = 4)\n",
    "#     print(f'loss: {loss}')\n",
    "\n",
    "#     if not (i % 50):\n",
    "#         valid_loss = trainer.valid_step(unet_number = unet_training, max_batch_size = 4)\n",
    "#         print(f'valid loss: {valid_loss}')\n",
    "\n",
    "#     if not (i % 100) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "#         videos = trainer.sample(texts = texts, video_frames = 20, stop_at_unet_number=unet_training)\n",
    "#         pil_images = list(map(lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))), videos.swapdims(2,1)))\n",
    "\n",
    "#         for x in range(5):\n",
    "#             display(pil_images[0][x*4])\n",
    "#             pil_images[0][x*4].save(f'./samples/sample-{i // 100}_frame-{x*4}.png')\n",
    "\n",
    "# trainer.save(f'./checkpoint{unet_training}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728151b1-4dfe-4256-8ba6-ffb083807da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3941ec-8048-4d3d-b88c-0b252e1567a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b75cad-ef8c-4533-a96d-f8f98778e968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
